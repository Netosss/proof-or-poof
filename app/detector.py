import logging
import cv2
import numpy as np
import asyncio
import hashlib
from collections import OrderedDict
from app.c2pa_reader import get_c2pa_manifest
from app.runpod_client import run_deep_forensics

logger = logging.getLogger(__name__)

# LRU Cache implementation for forensic results
class LRUCache:
    def __init__(self, capacity: int = 1000):
        self.cache = OrderedDict()
        self.capacity = capacity

    def get(self, key):
        if key not in self.cache:
            return None
        self.cache.move_to_end(key)
        return self.cache[key]

    def put(self, key, value):
        if key in self.cache:
            self.cache.move_to_end(key)
        self.cache[key] = value
        if len(self.cache) > self.capacity:
            self.cache.popitem(last=False)

forensic_cache = LRUCache(capacity=1000)

def get_image_hash(file_path: str) -> str:
    """Generate a quick MD5 hash of the image to use for caching."""
    hasher = hashlib.md5()
    with open(file_path, 'rb') as f:
        # Read only the first 1MB for speed
        hasher.update(f.read(1024 * 1024))
    return hasher.hexdigest()

def _run_fft_sync(image_path: str) -> float:
    """Synchronous FFT math calculation with tuned sensitivity."""
    try:
        img = cv2.imread(image_path, 0)
        if img is None:
            return 0.0
        
        # Resize large images for consistency
        h, w = img.shape
        if h > 1024 or w > 1024:
            img = cv2.resize(img, (1024, 1024))

        dft = np.fft.fft2(img)
        dft_shift = np.fft.fftshift(dft)
        magnitude_spectrum = 20 * np.log(np.abs(dft_shift) + 1e-9)
        mean_val = np.mean(magnitude_spectrum)
        
        # Strictness: 2.0x mean
        peaks = np.sum(magnitude_spectrum > (mean_val * 2.0))
        
        # Normalized score
        score = min(peaks / 10000, 1.0)
        return float(score)
    except Exception as e:
        logger.error(f"Error in FFT analysis: {e}")
        return 0.0

async def get_fft_score(image_path: str) -> float:
    """Offloads CPU-heavy FFT math to a background thread."""
    return await asyncio.to_thread(_run_fft_sync, image_path)

async def detect_ai_media(file_path: str) -> dict:
    """
    Refined Consensus Engine.
    Stage 1: C2PA Early Exit (If signature exists, trust it and stop).
    Stage 2: Weighted Fallback (If no C2PA, add Human Bias and continue calculations).
    """
    
    # --- Layer 1: Metadata Check (C2PA) ---
    manifest = get_c2pa_manifest(file_path)
    l1_data = {
        "status": "not_found",
        "provider": None,
        "description": "No cryptographic signature found. Digital 'passport' may have been stripped."
    }
    
    is_verified_ai = False
    is_verified_human = False
    
    if manifest:
        gen_info = manifest.get("claim_generator_info", [])
        generator = gen_info[0].get("name", "Unknown AI") if gen_info else manifest.get("claim_generator", "Unknown AI")

        is_generative_ai = False
        assertions = manifest.get("assertions", [])
        for assertion in assertions:
            if assertion.get("label") == "c2pa.actions.v2":
                actions = assertion.get("data", {}).get("actions", [])
                for action in actions:
                    source_type = action.get("digitalSourceType", "")
                    if "trainedAlgorithmicMedia" in source_type:
                        is_generative_ai = True
                    desc = action.get("description", "").lower()
                    if any(term in desc for term in ["generative fill", "ai-modified", "edited with ai", "ai generated"]):
                        is_generative_ai = True
            if is_generative_ai: break

        if is_generative_ai:
            is_verified_ai = True
            l1_data = {"status": "verified_ai", "provider": generator, "description": f"Verified AI signature found. Generated by {generator}."}
        else:
            is_verified_human = True
            l1_data = {"status": "verified_human", "provider": generator, "description": "Verified human-captured content."}

        # --- EARLY EXIT (C2PA Exists) ---
        # If the file has a signature (AI or Human), we trust it 100% as the Source of Truth.
        return {
            "summary": "Verified AI" if is_verified_ai else "Verified Human",
            "confidence_score": 1.0,
            "layers": {
                "layer1_metadata": l1_data,
                "layer2_forensics": {
                    "status": "skipped", 
                    "probability": 1.0 if is_verified_ai else 0.0, 
                    "signals": ["Source verified via cryptographic signature."]
                }
            }
        }

    # --- Stage 2: No C2PA Found (Weighted Fallback) ---
    # Since C2PA is missing, we bias the result towards "Human" (Giving benefit of the doubt)
    human_benefit_of_doubt = -0.20 # -20% AI probability bias
    
    # Layer 2: FFT Math
    fft_score = await get_fft_score(file_path)
    
    # Layer 3: Deep Forensic
    img_hash = get_image_hash(file_path)
    cached_score = forensic_cache.get(img_hash)
    if cached_score is not None:
        deep_score = cached_score
    else:
        deep_score = await run_deep_forensics(file_path)
        forensic_cache.put(img_hash, deep_score)
    
    # Calculate Forensic Probability
    # Deep Score is 97% of the math, FFT is 3% (Refined per recommendations)
    forensic_probability = (deep_score * 0.97) + (fft_score * 0.03)
    
    # Apply the Human Bias for missing metadata
    forensic_probability = max(0.0, min(1.0, forensic_probability + human_benefit_of_doubt))
    
    l2_data = {
        "status": "detected" if forensic_probability > 0.85 else "suspicious" if forensic_probability > 0.5 else "not_detected",
        "probability": round(forensic_probability, 4),
        "signals": []
    }
    
    if deep_score > 0.85: l2_data["signals"].append("Deep Learning identifies generative AI textures")
    if fft_score > 0.7: l2_data["signals"].append("Artificial frequency patterns detected (FFT)")
    l2_data["signals"].append("Missing metadata (Benefit of the doubt applied)")

    # --- Verdict Logic (Refined thresholds per recommendations) ---
    if forensic_probability > 0.92: summary = "Likely AI (High Confidence)"
    elif forensic_probability > 0.75: summary = "Possible AI (Forensic Match)"
    elif forensic_probability > 0.5: summary = "Suspicious (Inconsistent Pixels)"
    elif forensic_probability > 0.2: summary = "Likely Human (Minor Noise)"
    else: summary = "Likely Human"
    
    confidence_score = forensic_probability if forensic_probability > 0.5 else (1.0 - forensic_probability)
        
    return {
        "summary": summary,
        "confidence_score": round(confidence_score, 2),
        "layers": {"layer1_metadata": l1_data, "layer2_forensics": l2_data}
    }
