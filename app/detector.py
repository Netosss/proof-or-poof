import logging
import cv2
import numpy as np
import asyncio
import hashlib
from functools import lru_cache
from app.c2pa_reader import get_c2pa_manifest
from app.runpod_client import run_deep_forensics

logger = logging.getLogger(__name__)

# Simple in-memory cache to prevent redundant RunPod calls for the same image
# Stores: {image_hash: forensic_score}
forensic_cache = {}

def get_image_hash(file_path: str) -> str:
    """Generate a quick MD5 hash of the image to use for caching."""
    hasher = hashlib.md5()
    with open(file_path, 'rb') as f:
        # Read only the first 1MB for speed
        hasher.update(f.read(1024 * 1024))
    return hasher.hexdigest()

def _run_fft_sync(image_path: str) -> float:
    """Synchronous FFT math calculation."""
    try:
        img = cv2.imread(image_path, 0)
        if img is None:
            return 0.0
        dft = np.fft.fft2(img)
        dft_shift = np.fft.fftshift(dft)
        magnitude_spectrum = 20 * np.log(np.abs(dft_shift) + 1e-9)
        mean_val = np.mean(magnitude_spectrum)
        peaks = np.sum(magnitude_spectrum > (mean_val * 1.6))
        score = min(peaks / 5000, 1.0)
        return float(score)
    except Exception as e:
        logger.error(f"Error in FFT analysis: {e}")
        return 0.0

async def get_fft_score(image_path: str) -> float:
    """Offloads CPU-heavy FFT math to a background thread."""
    return await asyncio.to_thread(_run_fft_sync, image_path)

async def detect_ai_media(file_path: str) -> dict:
    """
    Optimized Consensus Engine.
    1. Metadata (Free)
    2. FFT Math (Free, Async)
    3. Deep Forensic (GPU, Cached)
    """
    
    # --- Layer 1: Metadata Check (C2PA) ---
    manifest = get_c2pa_manifest(file_path)
    l1_data = {
        "status": "not_found",
        "provider": None,
        "description": "No cryptographic signature found. Digital 'passport' may have been stripped."
    }
    
    is_verified_ai = False
    is_ai_modified = False
    is_verified_human = False
    
    if manifest:
        gen_info = manifest.get("claim_generator_info", [])
        generator = gen_info[0].get("name", "Unknown AI") if gen_info else manifest.get("claim_generator", "Unknown AI")

        is_generative_ai = False
        is_modified_by_ai = False
        
        assertions = manifest.get("assertions", [])
        for assertion in assertions:
            if assertion.get("label") == "c2pa.actions.v2":
                actions = assertion.get("data", {}).get("actions", [])
                for action in actions:
                    source_type = action.get("digitalSourceType", "")
                    desc = action.get("description", "").lower()
                    
                    if "trainedAlgorithmicMedia" in source_type:
                        is_generative_ai = True
                    if any(term in desc for term in ["generative fill", "ai-modified", "edited with ai"]):
                        is_modified_by_ai = True
                    if "generative ai" in desc or "ai generated" in desc:
                        is_generative_ai = True
            if is_generative_ai: break

        if is_generative_ai:
            is_verified_ai = True
            l1_data = {"status": "verified_ai", "provider": generator, "description": f"Verified AI signature found. Generated by {generator}."}
        elif is_modified_by_ai:
            is_ai_modified = True
            l1_data = {"status": "ai_modified", "provider": generator, "description": "Verified signature found, indicates AI modification."}
        else:
            is_verified_human = True
            l1_data = {"status": "verified_human", "provider": generator, "description": "Verified human-captured content."}

    # --- EARLY EXIT: Layer 1 (Metadata) ---
    if is_verified_ai or is_verified_human:
        return {
            "summary": "Verified AI" if is_verified_ai else "Verified Human",
            "confidence_score": 1.0,
            "layers": {
                "layer1_metadata": l1_data,
                "layer2_forensics": {"status": "skipped", "probability": 1.0 if is_verified_ai else 0.0, "signals": ["Verified via Metadata"]}
            }
        }

    # --- Layer 2: FFT Math (Async) ---
    fft_score = await get_fft_score(file_path)
    
    if fft_score > 0.9:
        return {
            "summary": "Likely AI (Pattern Match)",
            "confidence_score": round(fft_score, 2),
            "layers": {
                "layer1_metadata": l1_data,
                "layer2_forensics": {"status": "detected", "probability": round(fft_score, 4), "signals": ["Definitive artificial pattern (FFT)"]}
            }
        }

    # --- Layer 3: Deep Forensic (RunPod GPU with Caching) ---
    img_hash = get_image_hash(file_path)
    if img_hash in forensic_cache:
        logger.info("Forensic result found in cache. Skipping RunPod.")
        deep_score = forensic_cache[img_hash]
    else:
        logger.info("Offloading to RunPod GPU...")
        deep_score = await run_deep_forensics(file_path)
        # Store in cache (limit size in prod)
        if len(forensic_cache) > 1000: forensic_cache.clear()
        forensic_cache[img_hash] = deep_score
    
    forensic_probability = (deep_score * 0.85) + (fft_score * 0.15)
    
    l2_data = {
        "status": "detected" if forensic_probability > 0.7 else "suspicious" if forensic_probability > 0.3 else "not_detected",
        "probability": round(forensic_probability, 4),
        "signals": []
    }
    
    if deep_score > 0.8: l2_data["signals"].append("Deep Learning identifies generative AI textures")
    if fft_score > 0.5: l2_data["signals"].append("Artificial frequency patterns detected (FFT)")
    if not l2_data["signals"]: l2_data["signals"].append("Pixel DNA consistent with natural photography")

    # --- Consensus ---
    if is_ai_modified:
        summary, confidence_score = "AI Modified", 0.95
    else:
        if forensic_probability > 0.8: summary = "Likely AI (Forensic Match)"
        elif forensic_probability > 0.5: summary = "Possible AI (Suspicious Patterns)"
        elif forensic_probability > 0.2: summary = "Likely Human (Minor Noise)"
        else: summary = "Likely Human"
        confidence_score = forensic_probability if forensic_probability > 0.5 else (1.0 - forensic_probability)
        
    return {
        "summary": summary,
        "confidence_score": round(confidence_score, 2),
        "layers": {"layer1_metadata": l1_data, "layer2_forensics": l2_data}
    }
